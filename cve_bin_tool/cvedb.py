# Copyright (C) 2022 Intel Corporation
# SPDX-License-Identifier: GPL-3.0-or-later

"""
Handling CVE database
"""
from __future__ import annotations

import asyncio
import datetime
import logging
import os
import shutil
import sqlite3
from typing import Any

import requests
from rich.progress import track

from cve_bin_tool.async_utils import run_coroutine
from cve_bin_tool.error_handler import ErrorMode
from cve_bin_tool.log import LOGGER
from cve_bin_tool.sources import curl, nvd
from cve_bin_tool.version import check_latest_version

logging.basicConfig(level=logging.DEBUG)

# database defaults
DISK_LOCATION_DEFAULT = os.path.join(os.path.expanduser("~"), ".cache", "cve-bin-tool")
DISK_LOCATION_BACKUP = os.path.join(
    os.path.expanduser("~"), ".cache", "cve-bin-tool-backup"
)
DBNAME = "cve.db"
OLD_CACHE_DIR = os.path.join(os.path.expanduser("~"), ".cache", "cvedb")


class CVEDB:
    """
    Retrieves CVE data from sources and handles CVE Database
    """

    CACHEDIR = DISK_LOCATION_DEFAULT
    BACKUPCACHEDIR = DISK_LOCATION_BACKUP
    LOGGER = LOGGER.getChild("CVEDB")
    SOURCES = [nvd.NVD, curl.Curl]

    def __init__(
        self,
        sources=None,
        cachedir: str | None = None,
        backup_cachedir: str | None = None,
        version_check: bool = True,
        error_mode: ErrorMode = ErrorMode.TruncTrace,
    ):
        self.sources = (
            sources
            if sources is not None
            else [x(error_mode=error_mode) for x in self.SOURCES]
        )
        self.cachedir = cachedir if cachedir is not None else self.CACHEDIR
        self.backup_cachedir = (
            backup_cachedir if backup_cachedir is not None else self.BACKUPCACHEDIR
        )
        self.error_mode = error_mode

        # Will be true if refresh was successful
        self.was_updated = False

        # version update
        self.version_check = version_check

        # set up the db if needed
        self.dbpath = os.path.join(self.cachedir, DBNAME)
        self.connection: sqlite3.Connection | None = None

        self.data = []
        self.cve_count = -1
        self.all_cve_entries: list[dict[str, Any]] | None = None

        self.exploits_list = []
        self.exploit_count = 0

        if not os.path.exists(self.dbpath):
            self.rollback_cache_backup()

    def get_cve_count(self) -> int:
        if self.cve_count == -1:
            # Force update
            self.check_cve_entries()
        return self.cve_count

    def check_db_exists(self) -> bool:
        return os.path.isfile(self.dbpath)

    def get_db_update_date(self) -> float:
        # last time when CVE data was updated
        self.time_of_last_update = datetime.datetime.fromtimestamp(
            os.path.getmtime(self.dbpath)
        )
        return os.path.getmtime(self.dbpath)

    async def refresh(self) -> None:
        """Refresh the cve database and check for new version."""
        # refresh the database
        if not os.path.isdir(self.cachedir):
            os.makedirs(self.cachedir)

        # check for the latest version
        if self.version_check:
            check_latest_version()

        await self.get_data()

    def refresh_cache_and_update_db(self) -> None:
        self.LOGGER.debug("Updating CVE data. This will take a few minutes.")
        # refresh the nvd cache
        run_coroutine(self.refresh())

        # if the database isn't open, open it
        self.init_database()
        self.populate_db()

    def get_cvelist_if_stale(self) -> None:
        """Update if the local db is more than one day old.
        This avoids the full slow update with every execution.
        """
        if not os.path.isfile(self.dbpath) or (
            datetime.datetime.today()
            - datetime.datetime.fromtimestamp(os.path.getmtime(self.dbpath))
        ) > datetime.timedelta(hours=24):
            self.refresh_cache_and_update_db()
            self.time_of_last_update = datetime.datetime.today()
        else:
            self.time_of_last_update = datetime.datetime.fromtimestamp(
                os.path.getmtime(self.dbpath)
            )
            self.LOGGER.info(
                "Using cached CVE data (<24h old). Use -u now to update immediately."
            )
            self.db_open()
            if not self.latest_schema(self.connection.cursor()):
                self.refresh_cache_and_update_db()
                self.time_of_last_update = datetime.datetime.today()
            else:
                self.db_close()

    def latest_schema(self, cursor: sqlite3.Cursor) -> bool:
        """Check database is using latest schema"""
        self.LOGGER.debug("Check database is using latest schema")
        schema_check = "SELECT * FROM cve_severity WHERE 1=0"
        result = cursor.execute(schema_check)
        schema_latest = False
        # Look through column names and check for column added in latest schema
        for col_name in result.description:
            if col_name[0] == "cvss_vector":
                schema_latest = True
        return schema_latest

    def check_cve_entries(self) -> bool:
        """Report if database has some CVE entries"""
        self.db_open()
        cursor = self.connection.cursor()
        cve_entries_check = "SELECT COUNT(*) FROM cve_severity"
        cursor.execute(cve_entries_check)
        # Find number of entries
        cve_entries = cursor.fetchone()[0]
        self.LOGGER.info(f"There are {cve_entries} CVE entries in the database")
        self.db_close()
        self.cve_count = cve_entries
        return cve_entries > 0

    def init_database(self) -> None:
        """Initialize db tables used for storing cve/version data"""
        self.db_open()
        cursor = self.connection.cursor()
        cve_data_create = """
        CREATE TABLE IF NOT EXISTS cve_severity (
            cve_number TEXT,
            severity TEXT,
            description TEXT,
            score INTEGER,
            cvss_version INTEGER,
            cvss_vector TEXT,
            PRIMARY KEY(cve_number)
        )
        """
        version_range_create = """
        CREATE TABLE IF NOT EXISTS cve_range (
            cve_number TEXT,
            vendor TEXT,
            product TEXT,
            version TEXT,
            versionStartIncluding TEXT,
            versionStartExcluding TEXT,
            versionEndIncluding TEXT,
            versionEndExcluding TEXT,
            FOREIGN KEY(cve_number) REFERENCES cve_severity(cve_number)
        )
        """
        index_range = "CREATE INDEX IF NOT EXISTS product_index ON cve_range (cve_number, vendor, product)"
        cursor.execute(cve_data_create)
        cursor.execute(version_range_create)
        cursor.execute(index_range)

        # Check that latest schema is being used
        if not self.latest_schema(cursor):
            # Recreate table using latest schema
            self.LOGGER.info("Upgrading database to latest schema")
            cursor.execute("DROP TABLE cve_severity")
            cursor.execute(cve_data_create)
            self.clear_cached_data()
        self.connection.commit()

    async def get_data(self):
        """Get CVE data from datasources"""

        tasks = []

        for source in self.sources:
            if source is not None:
                tasks.append(source.get_cve_data())

        for r in await asyncio.gather(*tasks):
            self.data.append(r)

    def populate_db(self) -> None:
        """Function that populates the database from the JSON.

        WARNING: After some inspection of the data, we are assuming that start/end ranges are kept together
        in single nodes.  This isn't *required* by the json so may not be true everywhere.  If that's the case,
        we'll need a better parser to match those together.
        """

        self.db_open()
        cursor = self.connection.cursor()

        for severity_data, affected_data in self.data:
            if severity_data is not None:
                self.populate_severity(
                    severity_data,
                    cursor,
                )
            if affected_data is not None:
                self.populate_affected(
                    affected_data,
                    cursor,
                )

        self.connection.commit()

        self.db_close()

    def populate_severity(self, severity_data, cursor):
        insert_severity = """
        INSERT or REPLACE INTO cve_severity(
            CVE_number,
            severity,
            description,
            score,
            cvss_version,
            cvss_vector
        )
        VALUES (?, ?, ?, ?, ?, ?)
        """

        del_cve_range = "DELETE from cve_range where CVE_number=?"

        for cve in severity_data:
            cursor.execute(
                insert_severity,
                [
                    cve["ID"],
                    cve["severity"],
                    cve["description"],
                    cve["score"],
                    cve["CVSS_version"],
                    cve["CVSS_vector"],
                ],
            )

            # Delete any old range entries for this CVE_number
            cursor.execute(del_cve_range, (cve["ID"],))

    def populate_affected(self, affected_data, cursor):

        insert_cve_range = """
        INSERT or REPLACE INTO cve_range(
            cve_number,
            vendor,
            product,
            version,
            versionStartIncluding,
            versionStartExcluding,
            versionEndIncluding,
            versionEndExcluding
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """

        cursor.executemany(
            insert_cve_range,
            [
                (
                    affected["cve_id"],
                    affected["vendor"],
                    affected["product"],
                    affected["version"],
                    affected["versionStartIncluding"],
                    affected["versionStartExcluding"],
                    affected["versionEndIncluding"],
                    affected["versionEndExcluding"],
                )
                for affected in affected_data
            ],
        )

    def clear_cached_data(self) -> None:
        self.create_cache_backup()
        if os.path.exists(self.cachedir):
            self.LOGGER.warning(f"Updating cachedir {self.cachedir}")
            shutil.rmtree(self.cachedir)
        # Remove files associated with pre-1.0 development tree
        if os.path.exists(OLD_CACHE_DIR):
            self.LOGGER.warning(f"Deleting old cachedir {OLD_CACHE_DIR}")
            shutil.rmtree(OLD_CACHE_DIR)

    def get_vendor_product_pairs(self, package_names) -> list[dict[str, str]]:
        """
        Fetches vendor from the database for packages that doesn't have vendor info for Package List Parser Utility and Universal Python package checker.
        """
        self.db_open()
        cursor = self.connection.cursor()
        vendor_package_pairs = []
        query = """
        SELECT DISTINCT vendor FROM cve_range
        WHERE product=?
        """

        # For python package checkers we don't need the progress bar running
        if type(package_names) != list:
            cursor.execute(query, [package_names])
            vendors = list(map(lambda x: x[0], cursor.fetchall()))
            for vendor in vendors:
                if vendor != "":
                    vendor_package_pairs.append(
                        {
                            "vendor": vendor,
                            "product": package_names,
                        }
                    )
            if len(vendor_package_pairs) > 1:
                self.LOGGER.debug(f"Multiple vendors found for {package_names}")
                for entry in vendor_package_pairs:
                    self.LOGGER.debug(f'{entry["product"]} - {entry["vendor"]}')
        else:
            for package_name in track(
                package_names, description="Processing the given list...."
            ):
                cursor.execute(query, [package_name["name"].lower()])
                vendors = list(map(lambda x: x[0], cursor.fetchall()))
                for vendor in vendors:
                    if vendor != "":
                        vendor_package_pairs.append(
                            {
                                "vendor": vendor,
                                "product": package_name["name"],
                            }
                        )
        self.db_close()
        return vendor_package_pairs

    def db_open(self) -> None:
        """Opens connection to sqlite database."""
        if not self.connection:
            self.connection = sqlite3.connect(self.dbpath)

    def db_close(self) -> None:
        """Closes connection to sqlite database."""
        if self.connection:
            self.connection.close()
            self.connection = None

    def create_cache_backup(self) -> None:
        """Creates a backup of the cachedir in case anything fails"""
        if os.path.exists(self.cachedir):
            self.LOGGER.debug(
                f"Creating backup of cachedir {self.cachedir} at {self.backup_cachedir}"
            )
            self.remove_cache_backup()
            shutil.copytree(self.cachedir, self.backup_cachedir)

    def copy_db(self, filename, export=True):
        self.db_close()
        if export:
            shutil.copy(self.dbpath, filename)
        else:
            shutil.copy(filename, self.dbpath)

    def remove_cache_backup(self) -> None:
        """Removes the backup if database was successfully loaded"""
        if os.path.exists(self.backup_cachedir):
            self.LOGGER.debug(f"Removing backup cache from {self.backup_cachedir}")
            shutil.rmtree(self.backup_cachedir)

    def rollback_cache_backup(self) -> None:
        """Rollback the cachedir backup in case anything fails"""
        if os.path.exists(os.path.join(self.backup_cachedir, DBNAME)):
            self.LOGGER.info("Rolling back the cache to its previous state")
            if os.path.exists(self.cachedir):
                shutil.rmtree(self.cachedir)
            shutil.move(self.backup_cachedir, self.cachedir)

    def __del__(self) -> None:
        self.rollback_cache_backup()

    # Methods to check and update exploits

    def update_exploits(self):
        url = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
        r = requests.get(url)
        data = r.json()
        cves = data["vulnerabilities"]
        exploit_list = []
        for cve in cves:
            exploit_list.append((cve["cveID"], cve["product"], cve["shortDescription"]))
        self.populate_exploit_db(exploit_list)

    def get_cache_exploits(self):
        get_exploits = """
        SELECT cve_number FROM cve_exploited
        """
        self.db_open()
        cursor = self.connection.cursor()
        cursor.row_factory = lambda cursor, row: row[0]
        self.exploits_list = cursor.execute(get_exploits).fetchall()
        self.db_close()
        self.exploit_count = len(self.exploits_list)

    def get_exploits_list(self):
        return self.exploits_list

    def get_exploits_count(self):
        return self.exploit_count

    def create_exploit_db(self):
        create_exploit_table = """
        CREATE TABLE IF NOT EXISTS cve_exploited (
            cve_number TEXT,
            product TEXT,
            description TEXT,
            PRIMARY KEY(cve_number)
        )
        """
        self.db_open()
        cursor = self.connection.cursor()
        cursor.execute(create_exploit_table)
        self.connection.commit()
        self.db_close()

    def populate_exploit_db(self, exploits):
        insert_exploit = """
        INSERT or REPLACE INTO cve_exploited (
            cve_number,
            product,
            description
        )
        VALUES (?,?,?)
        """
        self.db_open()
        cursor = self.connection.cursor()
        cursor.executemany(insert_exploit, exploits)
        self.connection.commit()
        self.db_close()
