"""
Retrieval access and caching of NIST CVE database
"""
import os
import re
import gzip
import json
import glob
import shutil
import sqlite3
import hashlib
import logging
import tempfile
import functools
import traceback
import contextlib
import multiprocessing

try:
    import urllib.request as request
except:
    import urllib2 as request

from collections import namedtuple
from .log import LOGGER

logging.basicConfig(level=logging.DEBUG)

# database defaults
DISK_LOCATION_DEFAULT = os.path.join(os.path.expanduser("~"), ".cache", "cvedb")
DBNAME = "cve.db"


class EmptyCache(Exception):
    """
    Raised when NVD is opened when verify=False and there are no files in the
    cache.
    """


class CVEDataForYearNotInCache(Exception):
    """
    Raised when the CVE data for a year is not present in the cache.
    """


class AttemptedToWriteOutsideCachedir(Exception):
    """
    Raised if we attempted to write to a file that would have been outside the
    cachedir.
    """


class SHAMismatch(Exception):
    """
    Raised if the sha of a file in the cache was not what it should be.
    """


def log_traceback(func, *args, **kwargs):
    """
    Multiprocessing won't print tracebacks, so log them
    """
    logger = logging.getLogger(__name__ + "." + func.__name__)
    try:
        return func(*args, logger=logger, **kwargs)
    except:
        logger.error(traceback.format_exc().strip())
        raise


def getmeta(metaurl, logger=LOGGER):
    with contextlib.closing(request.urlopen(metaurl)) as response:
        return (
            metaurl.replace(".meta", ".json.gz"),
            dict(
                [
                    line.split(":", 1)
                    for line in (response.read().decode()).split("\r\n")
                    if ":" in line
                ]
            ),
        )


def cache_update(cachedir, url, sha, chunk_size=16 * 1024, logger=LOGGER):
    """
    Update the cache for a single year of NVD data.
    """
    filename = url.split("/")[-1].replace(".gz", "")
    # Ensure we only write to files within the cachedir
    filepath = os.path.abspath(os.path.join(cachedir, filename))
    if not filepath.startswith(os.path.abspath(cachedir)):
        raise AttemptedToWriteOutsideCachedir(filepath)
    # Validate the contents of the cached file
    if os.path.isfile(filepath):
        # Validate the sha and write out
        sha = sha.upper()
        calculate = hashlib.sha256()
        with open(filepath, "rb") as handle:
            chunk = handle.read(chunk_size)
            while chunk:
                calculate.update(chunk)
                chunk = handle.read(chunk_size)
        # Validate the sha and exit if it is correct, otherwise update
        gotsha = calculate.hexdigest().upper()
        if gotsha != sha:
            os.unlink(filepath)
            logger.critical(
                "SHA mismatch for %s (have: %r, want: %r)", filename, gotsha, sha
            )
        else:
            logger.debug("Correct SHA for %s", filename)
            return
    logger.info("Updating CVE cache for %s", filename)
    with tempfile.TemporaryFile(prefix="cvedb-") as temp_file:
        with contextlib.closing(request.urlopen(url)) as response:
            # Write to tempfile (gzip doesnt support reading from urlopen on
            # Python 2)
            shutil.copyfileobj(response, temp_file)
        # Replace the file with the tempfile
        temp_file.seek(0)
        with gzip.GzipFile(fileobj=temp_file, mode="rb") as jsondata_fileobj:
            # Validate the sha
            sha = sha.upper()
            calculate = hashlib.sha256()
            # Copy the contents while updating the sha
            with open(filepath, "wb") as filepath_handle:
                chunk = jsondata_fileobj.read(chunk_size)
                while chunk:
                    calculate.update(chunk)
                    filepath_handle.write(chunk)
                    chunk = jsondata_fileobj.read(chunk_size)
            # Raise error if there was an issue with the sha
            gotsha = calculate.hexdigest().upper()
            if gotsha != sha:
                # Remove the file if there was an issue
                os.unlink(filepath)
                raise SHAMismatch("{} (have: {}, want: {})".format(url, gotsha, sha))


class CVEDB(object):
    """
    Downloads NVD data in json form and stores it on disk in a cache.
    """

    CACHEDIR = os.path.join(os.path.expanduser("~"), ".cache", "cvedb")
    FEED = "https://nvd.nist.gov/vuln/data-feeds"
    LOGGER = LOGGER.getChild("CVEDB")
    NVDCVE_FILENAME_TEMPLATE = "nvdcve-1.1-{}.json"
    META_REGEX = re.compile("https:\/\/.*\/json\/.*-[0-9]*\.[0-9]*-[0-9]*\.meta")

    def __init__(self, verify=True, feed=None, cachedir=None):
        self.verify = verify
        self.feed = feed if feed is not None else self.FEED
        self.cachedir = cachedir if cachedir is not None else self.CACHEDIR
        # Will be true if refresh was successful
        self.was_updated = False

        # set up the db if needed
        self.disk_location = DISK_LOCATION_DEFAULT
        self.dbname = os.path.join(self.disk_location, DBNAME)
        self.connection = None

    def nist_scrape(self, feed):
        with contextlib.closing(request.urlopen(feed)) as response:
            page = response.read().decode()
            jsonmetalinks = self.META_REGEX.findall(page)
            pool = multiprocessing.Pool()
            try:
                metadata = dict(
                    pool.map(
                        functools.partial(log_traceback, getmeta), tuple(jsonmetalinks)
                    )
                )
                pool.close()
                return metadata
            except:
                pool.terminate()
                raise
            finally:
                pool.join()

    def init_database(self):
        """ Initialize db tables used for storing cve/version data """
        conn = sqlite3.connect(self.dbname)
        db_cursor = conn.cursor()
        cve_data_create = """CREATE TABLE IF NOT EXISTS cve_data (
        cve_number TEXT,
        severity TEXT,
        score INTEGER,
        cvss_version INTEGER,
        PRIMARY KEY(cve_number)
        )
        """
        db_cursor.execute(cve_data_create)

        version_single_create = """ CREATE TABLE IF NOT EXISTS version_single (
        cve_number TEXT,
        vendor TEXT,
        product TEXT,
        version TEXT,
        UNIQUE(cve_number, vendor, product, version)
        )
        """
        db_cursor.execute(version_single_create)

        version_range_create = """ CREATE TABLE IF NOT EXISTS version_range (
        cve_number TEXT,
        vendor TEXT,
        product TEXT,
        versionStartIncluding TEXT,
        versionStartExcluding TEXT,
        versionEndExcluding TEXT,
        versionEndIncluding TEXT
        )
        """
        db_cursor.execute(version_range_create)
        # FIXME: Add indices?
        return conn

    def open(self):
        """ Opens connection to sqlite database."""
        self.connection = sqlite3.connect(self.dbname, check_same_thread=False)

    def close(self):
        """ Closes connection to sqlite database."""
        self.connection.close()
        self.connection = None

    def __enter__(self):
        """ Opens connection to sqlite database."""
        self.open()

    def __exit__(self, exc_type, exc, exc_tb):
        """ Closes connection to sqlite database."""
        self.close()

    def get_cves(self, vendor, product, version):
        """ Get CVEs against a specific version of a package.

        Example:
            nvd.get_cves('haxx', 'curl', '7.34.0')
        """
        if self.connection is None:
            self.open()
        cursor = self.connection.cursor()
        query = """SELECT CVE_number FROM version_single WHERE
        vendor=? AND product=? AND version like ?"""
        cursor.execute(query, [vendor, product, version])

        return cursor.fetchall()

    def populate_db(self, connection):
        """ Test function that could eventually put data in the db """
        cursor = connection.cursor()

        # eventually: for year in years()
        cve_data = self.year(2019)
        for cve_item in cve_data["CVE_Items"]:
            self.LOGGER.debug(cve_item["cve"]["CVE_data_meta"]["ID"])
            # the information we want:
            # CVE ID, Severity, Score
            # affected {Vendor(s), Product(s), Version(s)}
            CVE = dict()
            CVE["ID"] = cve_item["cve"]["CVE_data_meta"]["ID"]

            # Get CVSSv3 or CVSSv2 score for output.
            # Details are left as an exercise to the user.
            CVE["severity"] = "unknown"
            CVE["score"] = "unknown"
            CVE["CVSS_version"] = "unknown"
            if "baseMetricV3" in cve_item["impact"]:
                CVE["severity"] = cve_item["impact"]["baseMetricV3"]["cvssV3"][
                    "baseSeverity"
                ]
                CVE["score"] = cve_item["impact"]["baseMetricV3"]["cvssV3"]["baseScore"]
                CVE["CVSS_version"] = 3
            elif "baseMetricV2" in cve_item["impact"]:
                CVE["severity"] = cve_item["impact"]["baseMetricV2"]["severity"]
                CVE["score"] = cve_item["impact"]["baseMetricV2"]["cvssV2"]["baseScore"]
                CVE["CVSS_version"] = 2

            self.LOGGER.debug(
                "Severity: {} ({}) v{}".format(
                    CVE["severity"], CVE["score"], CVE["CVSS_version"]
                )
            )

            q = "INSERT or REPLACE INTO cve_data(CVE_number, severity, score, cvss_version) \
            VALUES (?, ?, ?, ?)"
            cursor.execute(
                q, [CVE["ID"], CVE["severity"], CVE["score"], CVE["CVSS_version"]]
            )

            # walk the nodes with version data
            # return list of versions
            affects_list = []
            if "configurations" in cve_item:
                for node in cve_item["configurations"]["nodes"]:
                    self.LOGGER.debug("NODE: {}".format(node))
                    affects_list.extend(self.parse_node(node))
                    if "children" in node:
                        for child in node["children"]:
                            affects_list.extend(self.parse_node(child))
            self.LOGGER.debug("Affects: {}".format(affects_list))

            q = "INSERT or REPLACE INTO version_single(cve_number, vendor, product, version) \
            VALUES (?, ?, ?, ?)"
            for affected in affects_list:
                cursor.execute(
                    q,
                    [
                        CVE["ID"],
                        affected["vendor"],
                        affected["product"],
                        affected["version"],
                    ],
                )

        connection.commit()

    def parse_node(self, node):
        affects_list = []
        if "cpe_match" in node:
            for cpe_match in node["cpe_match"]:
                self.LOGGER.debug(cpe_match["cpe23Uri"])
                cpe_split = cpe_match["cpe23Uri"].split(":")
                affects = dict()
                affects["vendor"] = cpe_split[3]
                affects["product"] = cpe_split[4]
                affects["version"] = cpe_split[5]
                self.LOGGER.debug(
                    "Vendor: {} Product: {} Version: {}".format(
                        affects["vendor"], affects["product"], affects["version"]
                    )
                )
                if affects["version"] is "*":
                    # Not Dealing with ranges yet, but let's at least get start/end in
                    if "versionStartIncluding" in cpe_match:
                        self.LOGGER.debug(
                            "versionStartIncluding: {}".format(
                                cpe_match["versionStartIncluding"]
                            )
                        )
                        affects["version"] = cpe_match["versionStartIncluding"]
                        affects_list.append(affects)

                    if "versionEndIncluding" in cpe_match:
                        self.LOGGER.debug(
                            "versionEndIncluding: {}".format(
                                cpe_match["versionEndIncluding"]
                            )
                        )
                        affects["version"] = cpe_match["versionEndIncluding"]
                        affects_list.append(affects)
                else:
                    affects_list.append(affects)

                # When we get to ranges...
                """
                if "versionStartExcluding" in cpe_match:
                    self.LOGGER.debug(
                        "versionStartExcluding: {}".format(
                            cpe_match["versionStartExcluding"]
                        )
                    )
                if "versionEndExcluding" in cpe_match:
                    self.LOGGER.debug(
                        "versionEndExcluding: {}".format(
                            cpe_match["versionEndExcluding"]
                        )
                    )
                """
        return affects_list

    def refresh(self):
        if not os.path.isdir(self.cachedir):
            os.makedirs(self.cachedir)
        update = self.nist_scrape(self.feed)
        pool = multiprocessing.Pool()
        try:
            for result in [
                pool.apply_async(
                    functools.partial(log_traceback, cache_update),
                    (self.cachedir, url, meta["sha256"]),
                )
                for url, meta in update.items()
            ]:
                result.get()
            pool.close()
            self.was_updated = True
        except:
            pool.terminate()
            raise
        finally:
            pool.join()

    def year(self, year):
        """
        Return the dict of CVE data for the given year.
        """
        filename = os.path.join(
            self.cachedir, self.NVDCVE_FILENAME_TEMPLATE.format(year)
        )
        # Check if file exists
        if not os.path.isfile(filename):
            raise CVEDataForYearNotInCache(year)
        # Open the file and load the JSON data, log the number of CVEs loaded
        with open(filename, "rb") as fileobj:
            cves_for_year = json.load(fileobj)
            self.LOGGER.debug(
                "Year %d has %d CVEs in dataset", year, len(cves_for_year["CVE_Items"])
            )
            return cves_for_year

    def years(self):
        """
        Return the years we have NVD data for.
        """
        return sorted(
            [
                int(filename.split(".")[-2].split("-")[-1])
                for filename in glob.glob(
                    os.path.join(self.cachedir, "nvdcve-1.1-*.json")
                )
            ]
        )

    def __enter__(self):
        if not self.verify:
            self.LOGGER.error("Not verifying CVE DB cache")
            if not self.years():
                raise EmptyCache(self.cachedir)
        else:
            self.refresh()
        self.LOGGER.debug("Years present: %s", self.years())
        return self

    def __exit__(self, _exc_type, _exc_value, _traceback):
        pass


def refresh():
    with CVEDB():
        pass


if __name__ == "__main__":
    print("Experimenting...")
    cvedb = CVEDB(os.path.join(os.path.expanduser("~"), ".cache", "cvedb"))
    cvedb.refresh()
    print(cvedb.years())
    connection = cvedb.init_database()
    cvedb.populate_db(connection)
    print(cvedb.get_cves("tesla", "model_3", "-"))
