# Copyright (C) 2021 Intel Corporation
# SPDX-License-Identifier: GPL-3.0-or-later

import json
import os
from datetime import datetime
from logging import Logger
from typing import Dict, List

from .cvedb import DISK_LOCATION_DEFAULT
from .error_handler import ErrorHandler, ErrorMode, InvalidJsonError
from .input_engine import TriageData
from .log import LOGGER
from .util import DirWalk, ProductInfo


class MergeReports:
    def __init__(
        self,
        merge_files: List[str],
        format: str,
        output_file: str,
        logger: Logger = None,
        error_mode=ErrorMode.TruncTrace,
    ):
        self.logger = logger or LOGGER.getChild(self.__class__.__name__)
        self.merge_files = merge_files
        self.format = format
        self.output_file = output_file
        self.all_cve_data = []
        self.file_stack = []
        self.error_mode = error_mode
        self.total_inter_files = 0
        self.total_files = 0
        self.products_with_cve = 0
        self.products_without_cve = 0
        self.cache_dir = DISK_LOCATION_DEFAULT
        self.parsed_data: Dict[ProductInfo, TriageData] = None

        self.walker = DirWalk(
            pattern=";".join(
                file_path if file_path.endswith(".json") else file_path + "*.json"
                for file_path in merge_files
            ),
            yield_files=True,
        ).walk

    def recursive_scan(self, merge_files):
        for intermediate_path in merge_files:
            if os.path.isdir(intermediate_path):
                for filepath in self.walker([intermediate_path]):
                    self.file_stack.append(filepath)
                    yield filepath
                    self.file_stack.pop()
            elif os.path.isfile(intermediate_path) and not os.path.islink(
                intermediate_path
            ):
                self.file_stack.append(intermediate_path)
                yield intermediate_path
                self.file_stack.pop()

    def scan_intermediate_file(self, filename):
        self.logger.debug(f"Loading file: {filename}")

        with open(filename) as json_file:
            json_file = json_file.read()
            inter_data = json.loads(json_file)
            if not inter_data or not isinstance(inter_data, dict):
                with ErrorHandler(mode=self.error_mode):
                    raise InvalidJsonError(filename)

            if "metadata" in inter_data and "report" in inter_data:
                self.logger.info(
                    f"Adding data from {filename.split('/')[-1]} with timestamp {inter_data['metadata']['timestamp']}"
                )
                self.total_inter_files += 1
                return inter_data

        self.logger.warning(
            f"File {filename.split('/')[-1]} is not a valid intermediate report"
        )
        return []

    def merge_reports(self):
        for inter_file in self.recursive_scan(self.merge_files):
            # do something to remove duplicates and use the latest data if cve id is same
            self.all_cve_data.append(self.scan_intermediate_file(inter_file))

        if self.all_cve_data:
            self.all_cve_data = self.remove_intermediate_duplicates()
            merged_file_path = self.save_merged_intermediate()
        return merged_file_path

    def save_merged_intermediate(self):

        if not os.path.isdir(self.cache_dir):
            os.makedirs(self.cache_dir)

        now = datetime.now().strftime("%Y-%m-%d.%H-%M-%S")
        filename = os.path.join(self.cache_dir, f"merged-{now}.json")
        with open(filename, "w") as f:
            json.dump(self.all_cve_data, f, indent="    ")

        return filename

    def remove_intermediate_duplicates(self):
        output = {}
        for inter_data in self.all_cve_data:
            self.products_with_cve += inter_data["metadata"]["products_with_cve"]
            self.products_without_cve += inter_data["metadata"]["products_without_cve"]
            for cve in inter_data["report"]:
                if cve["cve_number"] != "UNKNOWN":
                    if cve["cve_number"] not in output:
                        output[cve["cve_number"]] = cve
                        self.total_files += len(cve["paths"].split(","))
                    else:
                        path_list = output[cve["cve_number"]]["paths"].split(",")
                        self.total_files -= len(path_list)
                        path_list.extend(cve["paths"].split(","))
                        # remove duplicate path list
                        path_list = list(set(path_list))
                        self.total_files += len(path_list)
                        output[cve["cve_number"]]["path"] = path_list

        return list(output.values())
