# Copyright (C) 2021 Intel Corporation
# SPDX-License-Identifier: GPL-3.0-or-later

"""
Retrieval access and of NVD entries using NVD Automatic CVE Retrieval
"""

import asyncio
import gzip
import json
import math
import os
from datetime import datetime
from logging import Logger
from typing import Union

import aiohttp
from rich.progress import Progress, track

from cve_bin_tool.async_utils import RateLimiter
from cve_bin_tool.error_handler import ErrorMode, NVDServiceError
from cve_bin_tool.log import LOGGER

NVD_FILENAME_TEMPLATE = "nvdcve-1.1-{}.json.gz"
DISK_LOCATION_DEFAULT = os.path.join(os.path.expanduser("~"), ".cache", "cve-bin-tool")


FEED = "https://services.nvd.nist.gov/rest/json/cves/1.0"

PAGESIZE = 2000
MAX_FAIL = 5
# Interval in seconds between successive requests
INTERVAL_PERIOD = 2


def filter_by_id(cve, update_data):
    """Function to filter out duplicate CVE entries in case of incremental update"""
    cve_id = cve["cve"]["CVE_data_meta"]["ID"]

    return all(
        cve_id != update_cve["cve"]["CVE_data_meta"]["ID"] for update_cve in update_data
    )


class NVD_API:
    def __init__(
        self,
        logger: Logger = LOGGER.getChild("NVD_API"),
        feed=FEED,
        session=None,
        page_size: int = PAGESIZE,
        max_fail: int = MAX_FAIL,
        interval: int = INTERVAL_PERIOD,
        outdir=DISK_LOCATION_DEFAULT,
        error_mode: ErrorMode = ErrorMode.TruncTrace,
    ):
        self.logger = logger or LOGGER.getChild(self.__class__.__name__)
        self.feed = feed
        self.session = session
        self.params = dict()
        self.page_size = page_size
        self.max_fail = max_fail
        self.interval = interval
        self.outdir = outdir
        self.error_mode = error_mode
        self.NVDCVE_FILENAME_TEMPLATE = NVD_FILENAME_TEMPLATE
        self.total_results = -1
        self.failed_count = 0
        self.year_wise_data = []

    @staticmethod
    def convert_date_to_nvd_date(date: datetime) -> str:
        """Returns a datetime string of NVD recognized date format"""
        UTC_OFFSET = datetime.now() - datetime.utcnow()
        utc_date = (date + UTC_OFFSET).strftime("%Y-%m-%dT%H:%M:%S:%f")[:-3]
        return f"{utc_date} UTC-00:00"

    async def filter_year_wise_data(self, year_wise_data) -> dict():
        """Returns a list of year-wise cve dictionary"""
        output = dict()
        for cve in year_wise_data:
            year = int(cve["publishedDate"][:4])
            if year not in output:
                output[year] = [cve]
            else:
                output[year].append(cve)
        return output

    async def get_nvd_params(
        self,
        time_of_last_update: Union[datetime, None] = None,
    ):
        """
        Initialize NVD request parameters
        """
        if time_of_last_update:
            # Fetch all cves from this date (even the updated ones)
            self.params["modStartDate"] = self.convert_date_to_nvd_date(
                time_of_last_update
            )
            self.logger.info(self.params["modStartDate"])
            self.logger.info(time_of_last_update)
            self.params["includeMatchStringChange"] = json.dumps(True)

            # Check modified strings inside CVEs as well

        self.params["startIndex"] = 0
        self.params["resultsPerPage"] = self.page_size

        if not self.session:
            connector = aiohttp.TCPConnector()
            self.session = RateLimiter(
                aiohttp.ClientSession(connector=connector, trust_env=True)
            )

        with Progress() as progress:
            task = progress.add_task(
                "Fetching metadata from NVD...", total=1, start=False
            )
            while await self.load_nvd_request(start_index=0):
                progress.update(task)
            progress.update(task, advance=1)

        self.logger.info(f"Total {self.total_results} entries found")

    async def load_nvd_request(self, start_index):
        """Get single NVD request and update year_wise_data list which contains list of all CVEs"""

        param_dict = self.params.copy()
        param_dict["startIndex"] = start_index

        fetched_data = None
        while fetched_data is None:
            try:
                async with await self.session.get(
                    self.feed,
                    params=param_dict,
                    raise_for_status=True,
                ) as response:
                    if response.status == 200:
                        fetched_data = await response.json()
                        if start_index == 0:
                            self.total_results = fetched_data["totalResults"]

                        self.year_wise_data.extend(fetched_data["result"]["CVE_Items"])

                        # await asyncio.sleep(0)
                    elif response.status == 503:
                        raise NVDServiceError(self.params["modStartDate"])
                    else:
                        self.failed_count += 1
                        if self.failed_count == self.max_fail:
                            self.logger.info(
                                f"Pausing requests for {self.interval} seconds"
                            )
                            self.failed_count = 0
                            await asyncio.sleep(self.interval)
                        else:
                            await asyncio.sleep(1)

            except aiohttp.ClientResponseError as error:
                self.logger.debug(f"Failed to connect to NVD {error}")
                self.logger.debug(f"Pausing requests for {self.interval} seconds")
                await asyncio.sleep(self.interval)

    async def get(self):
        """Calls load_nvd_request() multiple times to fetch all NVD feeds"""

        nvd_requests = [
            self.load_nvd_request(index * self.page_size)
            for index in range(
                1, 1 + int(math.ceil(self.total_results / self.page_size))
            )
        ]

        total_tasks = len(nvd_requests)
        # error_mode.value will only be greater than 1 if quiet mode.
        if self.error_mode.value > 1:
            iter_tasks = track(
                asyncio.as_completed(nvd_requests),
                description="Downloading Feeds from NVD...",
                total=total_tasks,
            )
        else:
            iter_tasks = asyncio.as_completed(nvd_requests)

        for task in iter_tasks:
            await task
        self.logger.info(
            "Updating cache using fetched NVD data. This will take some minutes..."
        )
        await self.update_nvd_data()

    async def replace_updated_nvd_data(self, all_cve_data, update_data):
        """
        Replace CVEs already available in case they are updated. Update `CVE_data_numberOfCVEs`
        """

        all_cve_data["CVE_Items"] = list(
            filter(
                lambda cve: filter_by_id(cve, update_data), all_cve_data["CVE_Items"]
            )
        )
        all_cve_data["CVE_Items"].extend(update_data)
        all_cve_data["CVE_data_numberOfCVEs"] = str(len(all_cve_data["CVE_Items"]))

        return all_cve_data

    async def save_nvd_year(self, year, new_cve_data):
        """
        Saves the dict of CVE data for the given year.
        """
        filename = os.path.join(self.outdir, self.NVDCVE_FILENAME_TEMPLATE.format(year))
        all_cve_year_data = None
        if not os.path.isfile(filename):
            self.logger.debug(
                f"Creating new file {self.NVDCVE_FILENAME_TEMPLATE.format(year)}"
            )
            all_cve_year_data = {
                "CVE_data_type": "CVE",
                "CVE_data_format": "MITRE",
                "CVE_data_version": "4.0",
                "CVE_data_numberOfCVEs": "0",
                "CVE_data_timestamp": datetime.now().strftime("%Y-%m-%dT%H:%MZ"),
                "CVE_Items": [],
            }
        else:
            with gzip.open(filename, "rt", encoding="utf-8") as file:
                all_cve_year_data = json.load(file)

        # Open the file and load the JSON data, log the number of CVEs loaded
        with gzip.open(filename, "wt", encoding="utf-8") as file:

            # Update common cves in cves_for_year to updated cve_date list
            cve_data = await self.replace_updated_nvd_data(
                all_cve_year_data, new_cve_data
            )

            json.dump(cve_data, file, indent=" ")
            self.logger.debug(
                f"Year {year} has been updated. It contains {len(cve_data['CVE_Items'])} CVEs in dataset now"
            )

    async def update_nvd_data(self):
        """
        Iterate save_nvd_year for saving the dict of CVE data for each year.
        """
        self.year_wise_data = await self.filter_year_wise_data(self.year_wise_data)
        years = list(self.year_wise_data.keys())

        nvd_update = [
            self.save_nvd_year(year, self.year_wise_data[year]) for year in years
        ]

        total_tasks = len(nvd_update)
        # error_mode.value will only be greater than 1 if quiet mode.
        if self.error_mode.value > 1:
            iter_tasks = track(
                nvd_update,
                description="Updating feeds in cache ...",
                total=total_tasks,
            )
        else:
            iter_tasks = asyncio.as_completed(nvd_update)

        for task in iter_tasks:
            await task
